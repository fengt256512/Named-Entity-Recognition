{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group43_A2_noval.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "861e5ab8fe424f81bc4900ece726b502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b98c84a785cd443bb3b6211a431e4f70",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_016bd5b3bcb74d4aa303c80e62d5ab30",
              "IPY_MODEL_8be74d5219c3497497ba0ba948b36b9e"
            ]
          }
        },
        "b98c84a785cd443bb3b6211a431e4f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "016bd5b3bcb74d4aa303c80e62d5ab30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2d73512316494c34b69efaefbcc40bc3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e96615f0ab948ab85dbec5f606c79e1"
          }
        },
        "8be74d5219c3497497ba0ba948b36b9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31d2172601404f57b15593a5806765a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 11.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42782e42a2b541d99d3bee23579b4952"
          }
        },
        "2d73512316494c34b69efaefbcc40bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e96615f0ab948ab85dbec5f606c79e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31d2172601404f57b15593a5806765a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42782e42a2b541d99d3bee23579b4952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27f9dfae12ed4427839412eb0cbed5c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e67fd5a5e5d8491c934dc0ee3ce1b8af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d2dc749d2b6442eb89cd4e91caec509",
              "IPY_MODEL_dcd8f83204e44b81a9e04b05317d6087"
            ]
          }
        },
        "e67fd5a5e5d8491c934dc0ee3ce1b8af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d2dc749d2b6442eb89cd4e91caec509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a07c15320ee546d7b437a3b197a03262",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e95c9bc80f9243e5a2e560519013f118"
          }
        },
        "dcd8f83204e44b81a9e04b05317d6087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a69356d47c64ef1978fff532af4a9e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 234kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aeff6ba3b084795883cae697580f889"
          }
        },
        "a07c15320ee546d7b437a3b197a03262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e95c9bc80f9243e5a2e560519013f118": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a69356d47c64ef1978fff532af4a9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aeff6ba3b084795883cae697580f889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24f1695ca2604633b4610b0108188f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0fb2eaea4b604dbebc79f2d0926dcc59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c87d4b24d1dc40deadc5617016f024d2",
              "IPY_MODEL_68105a9c75a74b14b0b743f3b1cd4bb5"
            ]
          }
        },
        "0fb2eaea4b604dbebc79f2d0926dcc59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c87d4b24d1dc40deadc5617016f024d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e71e315635944918b34f4589ea8e6948",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee06e7e6f23e46fabaa9059a8e62937c"
          }
        },
        "68105a9c75a74b14b0b743f3b1cd4bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f930f6667044a4baeb92d44b5eaf65f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 748kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cce33c432784db39cee426afe97a90c"
          }
        },
        "e71e315635944918b34f4589ea8e6948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee06e7e6f23e46fabaa9059a8e62937c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f930f6667044a4baeb92d44b5eaf65f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cce33c432784db39cee426afe97a90c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3fea6a3ada04a00a306ce84bf94a9c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f908faaab57b4d2ca1d45f0944c715ea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_88517038491c4efdab335bd1e47b5301",
              "IPY_MODEL_868ed079bde44604bc4b3f2e144f358e"
            ]
          }
        },
        "f908faaab57b4d2ca1d45f0944c715ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88517038491c4efdab335bd1e47b5301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bbfa3703afbe4293b9b3288ea743b43d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46ba9ca9e18d45839da63f303e902684"
          }
        },
        "868ed079bde44604bc4b3f2e144f358e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3920039598e04b378347ab82d83cfbd6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:01&lt;00:00, 14.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb01170f0cd1482a91f01a8f39d5c02e"
          }
        },
        "bbfa3703afbe4293b9b3288ea743b43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46ba9ca9e18d45839da63f303e902684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3920039598e04b378347ab82d83cfbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb01170f0cd1482a91f01a8f39d5c02e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89349c0ecb3244d8b23eb8970683217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b5cc5a26f0c24cf28ce3b05b1195bdc7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d3881e78954a4d06a552091d32b77c21",
              "IPY_MODEL_a3caf662585e444d930dc45f1cbd6fd5"
            ]
          }
        },
        "b5cc5a26f0c24cf28ce3b05b1195bdc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d3881e78954a4d06a552091d32b77c21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b193a8a2602448d990b9446929a23b76",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83f274a202a44273b7ddcb2551f2847e"
          }
        },
        "a3caf662585e444d930dc45f1cbd6fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c573db76d6e744b2bd51654bff1a5aca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 35.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_babce1af1c3a4f2fbabb75bbb1459284"
          }
        },
        "b193a8a2602448d990b9446929a23b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83f274a202a44273b7ddcb2551f2847e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c573db76d6e744b2bd51654bff1a5aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "babce1af1c3a4f2fbabb75bbb1459284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfUIc_Ha4iXh"
      },
      "source": [
        "# Code to download file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCN45LVgz3-7"
      },
      "source": [
        "# **0 - Data Download and Load**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve4crawxyxC1"
      },
      "source": [
        "# Data Download\n",
        "id = '1by3IklROS_bxiz4gnC1oGg9KGghvXnhD'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('test_without_labels.csv')  \n",
        "\n",
        "id = '1cDm7WUrE0BzUuT9O23Oz8vi9g5YsrSg7'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('train.csv')  \n",
        "\n",
        "id = '1SQSoK4IuILwjPMmjpp9-jd_Gh6ad7CYl'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('val.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sJIvcwD1VGR"
      },
      "source": [
        "# Data load\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_dataset = pd.read_csv('train.csv')\n",
        "val_dataset = pd.read_csv('val.csv')\n",
        "test_dataset = pd.read_csv('test_without_labels.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u27xHPiYLQY"
      },
      "source": [
        "# Get labels\n",
        "\n",
        "def get_labels(dataset):\n",
        "  labels_list = list(dataset.labels)\n",
        "  temp_labels = []\n",
        "  for labels in labels_list:\n",
        "    temp_labels.append(labels.split(\" \"))\n",
        "  return temp_labels\n",
        "\n",
        "# Labels\n",
        "train_labels = get_labels(train_dataset)\n",
        "val_labels = get_labels(val_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NobrR-gMJi78"
      },
      "source": [
        "# Get Sentences\n",
        "\n",
        "train_data = train_dataset.sents\n",
        "val_data = val_dataset.sents\n",
        "test_data = test_dataset.sents\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPC2CuVT1age"
      },
      "source": [
        "# **1 - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7kHNthpHvwr"
      },
      "source": [
        "# Remove punctuation inside words\n",
        "\n",
        "def remove_some_punctuation(sent_data):\n",
        "  temp_word = []\n",
        "  for idx, sentence in enumerate(sent_data):\n",
        "    temp = []\n",
        "    for word in sentence.split(' '):\n",
        "      if(('.' in word or '\\'' in word) and len(word)>1):\n",
        "        word = word.replace('\\'','')\n",
        "        word = word.replace('.', '')\n",
        "      temp.append(word)\n",
        "    temp_word.append(temp)\n",
        "  return temp_word\n",
        "\n",
        "test_words = remove_some_punctuation(test_data)\n",
        "val_words = remove_some_punctuation(val_data)\n",
        "train_words = remove_some_punctuation(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaO8Edj19oBG",
        "outputId": "949c42bc-28d1-4c18-c526-5bb023460599"
      },
      "source": [
        "# Tokenization on space\n",
        "# Lemmatization \n",
        "\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"wordnet\")\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def get_lemmatized(tokens):\n",
        "  lemmatized_tokens = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for token in tokens:\n",
        "    lemmatized = [lemmatizer.lemmatize(x.lower(), pos = 'v') for x in token]   \n",
        "    lemmatized_tokens.append(lemmatized)\n",
        "\n",
        "  return lemmatized_tokens\n",
        "\n",
        "train_tokens = get_lemmatized(train_words)\n",
        "val_tokens = get_lemmatized(val_words)\n",
        "test_tokens = get_lemmatized(test_words)\n",
        "all_tokens = train_tokens + val_tokens + test_tokens "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLapeBa_DYQC"
      },
      "source": [
        "# Generate word index\n",
        "\n",
        "def get_word_idx(tokens):\n",
        "  word_to_ix = {}\n",
        "  for sentence in tokens:\n",
        "    for word in sentence:\n",
        "      if word not in word_to_ix:\n",
        "        word_to_ix[word] = len(word_to_ix)\n",
        "  return word_to_ix\n",
        "\n",
        "# Generate label index\n",
        "def get_tag_idx(labels):\n",
        "  for tags in labels:\n",
        "    for tag in tags:\n",
        "      if tag not in tag_to_ix:\n",
        "        tag_to_ix[tag] = len(tag_to_ix)\n",
        "  return tag_to_ix\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG : 0, STOP_TAG : 1}\n",
        "\n",
        "word_to_ix = get_word_idx(all_tokens)\n",
        "word_list = list(word_to_ix.keys())\n",
        "tag_to_ix = get_tag_idx(train_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t08_OvJ3J9R8"
      },
      "source": [
        "# Get words index\n",
        "\n",
        "def get_index(dataset, to_idx):\n",
        "  input_index_list = []\n",
        "  for sentence in dataset:\n",
        "    input_index_list.append([to_idx[x] for x in sentence])\n",
        "  return input_index_list\n",
        "\n",
        "train_input_index = get_index(train_tokens, word_to_ix)\n",
        "train_output_index = get_index(train_labels, tag_to_ix)\n",
        "val_input_index = get_index(val_tokens, word_to_ix)\n",
        "val_output_index = get_index(val_labels, tag_to_ix)\n",
        "test_input_index = get_index(test_tokens, word_to_ix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beteNKXA1fEr"
      },
      "source": [
        "# **2 - Input Embedding**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUqjokZkddJa"
      },
      "source": [
        "## **Static Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L69tuC6a52sG"
      },
      "source": [
        "### **POS**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up8FDhwHEYys",
        "outputId": "06c0f1f3-62a0-47ef-cb84-abae6d6b22f4"
      },
      "source": [
        "# Generate POS tag\n",
        "# lab 6\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def get_pos_tag(tokens):\n",
        "  postags = []\n",
        "  for sentence in tokens:\n",
        "    tags = []\n",
        "    for word, tag in nltk.pos_tag(sentence):\n",
        "      tags.append(tag)\n",
        "    postags.append(tags)\n",
        "  return postags\n",
        "\n",
        "pos_tags = get_pos_tag(all_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0eLqz336eGU",
        "outputId": "c5261ec6-321a-4f87-fa53-282fc5d6b8a6"
      },
      "source": [
        "# Get the word vector of POS tag\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "wv_pos_model = Word2Vec(sentences = pos_tags, size = 50, window = 5, min_count = 1, workers = 4, sg = 1)\n",
        "\n",
        "wv_pos = {}\n",
        "for i in range(0,len(all_tokens)):\n",
        "  for j in range(0,len(all_tokens[i])):\n",
        "    wv_pos[all_tokens[i][j]] = wv_pos_model[pos_tags[i][j]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Qi8uOpUgHh",
        "outputId": "e809de1f-edf8-4582-a650-fb62df07fa30"
      },
      "source": [
        "# Generate POS embedding matrix\n",
        "\n",
        "pos_embedding_matrix = []\n",
        "\n",
        "for word in word_list:\n",
        "  temp_embedding = []\n",
        "  temp_embedding.extend(wv_pos[word])\n",
        "  pos_embedding_matrix.append(temp_embedding)\n",
        "\n",
        "\n",
        "pos_embedding_matrix = np.array(pos_embedding_matrix)\n",
        "pos_embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3351, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrbHuEN6qrP"
      },
      "source": [
        "### **Dependency parsing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YkHJTFb6h2T"
      },
      "source": [
        "#lab 7\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# parse-tree\n",
        "def get_parse_sentence(tokens):\n",
        "  parse_sentence = []\n",
        "  \n",
        "  for sentence in tokens:\n",
        "    parse = nlp(\" \".join(sentence))\n",
        "    temp = []\n",
        "    for sent in parse:\n",
        "      temp.append(sent.dep_)\n",
        "\n",
        "    parse_sentence.append(temp[:len(sentence)])\n",
        "\n",
        "  return parse_sentence\n",
        "\n",
        "parse_sentences = get_parse_sentence(all_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-iLPvvlexPO",
        "outputId": "c39f8ca5-2479-4c19-c307-fcdeb5ebedf9"
      },
      "source": [
        "# Get the word vector of Dependency Parse\n",
        "\n",
        "wv_parse_model = Word2Vec(sentences = parse_sentences, size = 50, window = 5, min_count = 1, workers = 4, sg = 1)\n",
        "\n",
        "wv_parse = {}\n",
        "for i in range(0, len(all_tokens)):\n",
        "  for j in range(0,len(all_tokens[i])):\n",
        "    wv_parse[all_tokens[i][j]] = wv_parse_model[parse_sentences[i][j]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTZL5BI_Uvpk",
        "outputId": "7c9630d5-ce4d-4807-bb2c-2adf7a8a2ca6"
      },
      "source": [
        "# Generate parse embedding matrix\n",
        "\n",
        "parse_embedding_matrix = []\n",
        "\n",
        "\n",
        "for word in word_list:\n",
        "  temp_embedding = []\n",
        "  temp_embedding.extend(wv_parse[word])\n",
        "  parse_embedding_matrix.append(temp_embedding)\n",
        "\n",
        "parse_embedding_matrix = np.array(parse_embedding_matrix)\n",
        "parse_embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3351, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aAugfSl0cnv"
      },
      "source": [
        "### **Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrpG6rCRH2pP",
        "outputId": "d5540bc4-f23a-428a-9982-2568b287d8f2"
      },
      "source": [
        "# Download pre-trained glove \n",
        "\n",
        "import gensim.downloader as api\n",
        "w2v_embedding_model = api.load(\"glove-twitter-50\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 199.5/199.5MB downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF7Nq_OFhsKQ",
        "outputId": "e4f9155c-f196-415d-bbbc-66ec31043c3e"
      },
      "source": [
        "#Generate word2vec embedding matrix\n",
        "\n",
        "w2v_embedding_matrix = []\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "for word in word_list:\n",
        "  temp_embedding = []\n",
        "  try:\n",
        "    temp_embedding.extend(w2v_embedding_model[word])\n",
        "    w2v_embedding_matrix.append(temp_embedding)\n",
        "\n",
        "  except:\n",
        "    w2v_embedding_matrix.append([0]* EMBEDDING_DIM)\n",
        "\n",
        "w2v_embedding_matrix = np.array(w2v_embedding_matrix)\n",
        "w2v_embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3351, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KJ8ouCNTKzw"
      },
      "source": [
        "## **Dynamic Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyJ2B_Vzu59n"
      },
      "source": [
        "### **Bert**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "861e5ab8fe424f81bc4900ece726b502",
            "b98c84a785cd443bb3b6211a431e4f70",
            "016bd5b3bcb74d4aa303c80e62d5ab30",
            "8be74d5219c3497497ba0ba948b36b9e",
            "2d73512316494c34b69efaefbcc40bc3",
            "2e96615f0ab948ab85dbec5f606c79e1",
            "31d2172601404f57b15593a5806765a0",
            "42782e42a2b541d99d3bee23579b4952",
            "27f9dfae12ed4427839412eb0cbed5c1",
            "e67fd5a5e5d8491c934dc0ee3ce1b8af",
            "3d2dc749d2b6442eb89cd4e91caec509",
            "dcd8f83204e44b81a9e04b05317d6087",
            "a07c15320ee546d7b437a3b197a03262",
            "e95c9bc80f9243e5a2e560519013f118",
            "6a69356d47c64ef1978fff532af4a9e3",
            "4aeff6ba3b084795883cae697580f889",
            "24f1695ca2604633b4610b0108188f02",
            "0fb2eaea4b604dbebc79f2d0926dcc59",
            "c87d4b24d1dc40deadc5617016f024d2",
            "68105a9c75a74b14b0b743f3b1cd4bb5",
            "e71e315635944918b34f4589ea8e6948",
            "ee06e7e6f23e46fabaa9059a8e62937c",
            "6f930f6667044a4baeb92d44b5eaf65f",
            "5cce33c432784db39cee426afe97a90c",
            "e3fea6a3ada04a00a306ce84bf94a9c1",
            "f908faaab57b4d2ca1d45f0944c715ea",
            "88517038491c4efdab335bd1e47b5301",
            "868ed079bde44604bc4b3f2e144f358e",
            "bbfa3703afbe4293b9b3288ea743b43d",
            "46ba9ca9e18d45839da63f303e902684",
            "3920039598e04b378347ab82d83cfbd6",
            "eb01170f0cd1482a91f01a8f39d5c02e",
            "89349c0ecb3244d8b23eb8970683217f",
            "b5cc5a26f0c24cf28ce3b05b1195bdc7",
            "d3881e78954a4d06a552091d32b77c21",
            "a3caf662585e444d930dc45f1cbd6fd5",
            "b193a8a2602448d990b9446929a23b76",
            "83f274a202a44273b7ddcb2551f2847e",
            "c573db76d6e744b2bd51654bff1a5aca",
            "babce1af1c3a4f2fbabb75bbb1459284"
          ]
        },
        "id": "QG1JMdQKF6up",
        "outputId": "c5058716-bb2c-478d-a04e-036a4fb19a25"
      },
      "source": [
        "# https://github.com/flairNLP/flair/blob/master/resources/docs/embeddings/TRANSFORMER_EMBEDDINGS.md\n",
        "# https://www.cnblogs.com/cuiyubo/p/10464504.html\n",
        "\n",
        "import torch\n",
        "!pip install flair\n",
        "import flair\n",
        "\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import BertEmbeddings\n",
        "\n",
        "from flair.embeddings import TransformerWordEmbeddings\n",
        "\n",
        "# init embedding\n",
        "bert_embedding = TransformerWordEmbeddings('bert-base-uncased')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 6.5MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.4MB/s \n",
            "\u001b[?25hCollecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 20.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/71/70/48a0bd55f79c328504fe6fe7ae8ff651f77a2aadbb1911701385d9bb5ca3/konoha-4.6.5-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 24.1MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Collecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/3c/e3/fb7b6aefaf0fc7b792cebbbd590b1895c022ab0ff27f389e1019c6f2e68a/huggingface_hub-0.0.10-py3-none-any.whl\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 17kB/s \n",
            "\u001b[?25hCollecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect->flair) (1.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.0.12)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Collecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/52/d0/bdb31463f2d9ca111e39b268518e9baa3542ef73ca449b711a7b4da69764/importlib_metadata-3.10.1-py3-none-any.whl\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 26.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 32.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9705 sha256=3e087a916beab2cc209593b220c8fbda4bca02e5a981bab1c7c6d41391b2e20c\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: ftfy, langdetect, mpld3, sqlitedict, segtok, overrides\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41935 sha256=eac16379b243660e6f506c6d32f918ae14bc53434b003de0a8bd59bd43d7817c\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993242 sha256=b7b1fa75e7ad4d4dd8733c834d6aa15bf5235ae4c4d51c9fea39fda8d4b2c628\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116704 sha256=c2477f5ecc3f5e70687a9507ca54c87c65f78b538b06c07151abfc700027e3ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14393 sha256=055cfda0c17ccc22f924fb88f55e2d64c9ff205d8b0a2897f82d3027976d01f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25031 sha256=883c938a648e22329065ab4647017a5baafa5e3784dea81eb21bc8d1bc078cab\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10187 sha256=eb4ed269a857acf5b96c1d7d95bd3fda2ec03d3dbe866bcc89157170b2985157\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built ftfy langdetect mpld3 sqlitedict segtok overrides\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: konoha 4.6.5 has requirement requests<3.0.0,>=2.25.1, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: transformers 4.6.1 has requirement huggingface-hub==0.0.8, but you'll have huggingface-hub 0.0.10 which is incompatible.\u001b[0m\n",
            "Installing collected packages: ftfy, langdetect, mpld3, gdown, overrides, importlib-metadata, konoha, tokenizers, sacremoses, huggingface-hub, transformers, janome, sqlitedict, sentencepiece, bpemb, torch, segtok, deprecated, flair\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "  Found existing installation: importlib-metadata 4.0.1\n",
            "    Uninstalling importlib-metadata-4.0.1:\n",
            "      Successfully uninstalled importlib-metadata-4.0.1\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.10 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.6.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata",
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "861e5ab8fe424f81bc4900ece726b502",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27f9dfae12ed4427839412eb0cbed5c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24f1695ca2604633b4610b0108188f02",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3fea6a3ada04a00a306ce84bf94a9c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89349c0ecb3244d8b23eb8970683217f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxILUkP0F6oW",
        "outputId": "10a425d5-2126-4863-8f54-c3b209c731c1"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "bert_embedding_matrix = []\n",
        "temp = []\n",
        "for word in tqdm(word_list):\n",
        "\n",
        "  sent = Sentence(word)\n",
        "  bert_embedding.embed(sent)\n",
        "  temp.append(sent)\n",
        "  for token in sent:\n",
        "    bert_embedding_matrix.append(token.embedding.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "bert_embedding_matrix = np.array(bert_embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3351/3351 [03:52<00:00, 14.38it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TjtW_Mrjsz5"
      },
      "source": [
        "## **Combination**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJEpfqOGF6lg"
      },
      "source": [
        "# concatenate both two matrix\n",
        "all_embedding_matrix = np.concatenate((bert_embedding_matrix, w2v_embedding_matrix, pos_embedding_matrix, parse_embedding_matrix), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyTeA0q8F6bP"
      },
      "source": [
        "word_bert_embedding_matrix = np.concatenate((bert_embedding_matrix, w2v_embedding_matrix), axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJAUqil1rWH"
      },
      "source": [
        "# **3 - NER Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RclmovwHkzkf"
      },
      "source": [
        "## **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li2dSvqtH2TR"
      },
      "source": [
        "# lab9\n",
        "# lab 10\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class Design_BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, stacked_layers = 1, use_crf = False, attention_method = None):\n",
        "        super(Design_BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "\n",
        "\n",
        "        self.layers = stacked_layers\n",
        "        self.use_crf = use_crf\n",
        "        self.attention_method = attention_method\n",
        "        self.general_attention_weight = nn.parameter.Parameter(torch.Tensor(1, self.hidden_dim, self.hidden_dim), requires_grad = True) # https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/nn/attention.html\n",
        "\n",
        "        \n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \"\"\"Using the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=self.layers, bidirectional=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.2) # After comparison, it is better than 0.5\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) if not attention_method else nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2 * self.layers, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2 * self.layers, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "    \n",
        "    def cal_attention(self, hidden, input_embedding, method,left,right):\n",
        "        # https://pytorch.org/docs/master/generated/torch.bmm.html\n",
        "        if method == 'Dot-product':\n",
        "          attn_weights = F.softmax(torch.bmm(left, right),dim=-1)\n",
        "        elif method == 'Scaled Dot-product':\n",
        "          attn_weights = F.softmax(torch.bmm(left, right) / np.sqrt(self.hidden_dim),dim=-1)\n",
        "        # General\n",
        "        # https://github.com/lmthang/nmt.hybrid\n",
        "        # https://nlp.stanford.edu/projects/nmt/\n",
        "        # https://stackoverflow.com/questions/50571991/implementing-luong-attention-in-pytorch\n",
        "        else: # General\n",
        "          left_step = torch.bmm(left, self.general_attention_weight)\n",
        "          right_step = torch.bmm(left_step, right)\n",
        "          attn_weights = F.softmax(right_step, dim=-1)\n",
        "        return attn_weights\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "        # with attention\n",
        "        if self.attention_method:\n",
        "          lstm_out = torch.squeeze(lstm_out, 1)\n",
        "          left_self = lstm_out.view(1, lstm_out.size(0), lstm_out.size(1))\n",
        "          right_self = left_self.view(left_self.size(0), left_self.size(2), left_self.size(1))\n",
        " \n",
        "          Attn_weight = self.cal_attention(lstm_out, embeds, self.attention_method,left_self,right_self)\n",
        "          output = torch.bmm(Attn_weight, left_self)\n",
        "          concat_output = torch.cat((output, left_self), dim = -1)\n",
        "          lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
        "\n",
        "        else:\n",
        "          lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        if self.use_crf == False:\n",
        "          lstm_feats = self._get_lstm_features(sentence)\n",
        "          return lstm_feats, list(torch.argmax(lstm_feats, -1).cpu().numpy())\n",
        "        else:\n",
        "          # Get the emission scores from the BiLSTM\n",
        "          lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "          # Find the best path, given the features.\n",
        "          score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "          return score, tag_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acVGllay2VE5"
      },
      "source": [
        "## **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXVyKd132lhG"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#lab 9\n",
        "def cal_acc(model, input_index, output_index):\n",
        "  ground_truth = []\n",
        "  predicted = []\n",
        "\n",
        "  for i,idxs in enumerate(input_index):\n",
        "      ground_truth += output_index[i]\n",
        "      score, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "      predicted += pred\n",
        "  accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "\n",
        "\n",
        "  return ground_truth, predicted, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJjzvSO54cAa"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A8fsxHIiQVp"
      },
      "source": [
        "import datetime\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "def train_dataset(model, epochs = 30, Lr = 0.015):\n",
        "  optimizer = optim.SGD(model.parameters(), lr = Lr, weight_decay = 1e-4)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  for epoch in tqdm(range(epochs)):  \n",
        "      time1 = datetime.datetime.now()\n",
        "      train_loss = 0\n",
        "\n",
        "      model.train()\n",
        "      for i, idxs in enumerate(input_index):\n",
        "          tags_index = output_index[i]\n",
        "\n",
        "          # Step 1. Remember that Pytorch accumulates gradients.\n",
        "          # We need to clear them out before each instance\n",
        "          model.zero_grad()\n",
        "\n",
        "          # Step 2. Get our inputs ready for the network, that is,\n",
        "          # turn them into Tensors of word indices.\n",
        "          sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "          targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "          # Step 3. Run our forward pass.\n",
        "          loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "          # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "          # calling optimizer.step()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_loss += loss.item()\n",
        "\n",
        "      max_val_acc=0\n",
        "      model.eval()\n",
        "      # Call the cal_acc functions you implemented as required\n",
        "      _, _, train_acc = cal_acc(model, train_input_index, train_output_index)\n",
        "      _, _, val_acc = cal_acc(model, val_input_index, val_output_index)\n",
        "\n",
        "      val_loss = 0\n",
        "      for i, idxs in enumerate(val_input_index):\n",
        "          tags_index = val_output_index[i]\n",
        "          sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "          targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "          loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "          val_loss+=loss.item()\n",
        "      time2 = datetime.datetime.now()\n",
        "\n",
        "      print(\"Epoch:%d, Training loss: %.2f, train acc: %.4f, val loss: %.2f, val acc: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au37g_tHnBpl"
      },
      "source": [
        "train_data = train_input_index \n",
        "train_label = train_output_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dilH_nqMogi5",
        "outputId": "ffde53fa-d9eb-451d-980e-ff012e97bc43"
      },
      "source": [
        "# Shuffle dataset\n",
        "from random import shuffle\n",
        "training_list = list(zip(train_data, train_label))\n",
        "shuffle(training_list)\n",
        "input_index = np.array([sentence[0] for sentence in training_list])\n",
        "output_index = np.array([sentence[1] for sentence in training_list])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEE4pc1XC--Q"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "def decode_output(output_list):\n",
        "  ix_to_tag = {v:k for k,v in tag_to_ix.items()}\n",
        "  return [ix_to_tag[output] for output in output_list]\n",
        "\n",
        "\n",
        "def get_f1score(model):\n",
        "  y_true, y_pred,_ = cal_acc(model, val_input_index, val_output_index)\n",
        "  y_true_decode = decode_output(y_true)\n",
        "  y_pred_decode = decode_output(y_pred)\n",
        "  f1 = f1_score(y_true_decode, y_pred_decode, average = 'micro')\n",
        "  return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEUM41f12iw8"
      },
      "source": [
        "# **4 - Evaluation**\n",
        "\n",
        "set up training process  with \n",
        "\n",
        "lr=0.015\n",
        "\n",
        "epoch =30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hmr0R-iIgQoZ"
      },
      "source": [
        "## **Restore result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpf1FXN6-kQu"
      },
      "source": [
        "ix_2_tag = {idx : tag for tag, idx in tag_to_ix.items()}\n",
        "\n",
        "def predict(model, input_index):\n",
        "  predicted=[]\n",
        "  for x in input_index:\n",
        "    input_tensor = torch.tensor(x).to(device)\n",
        "    _, output = model(input_tensor)\n",
        "    \n",
        "    for idx in output:\n",
        "      predicted.append(ix_2_tag[idx])\n",
        "  return predicted\n",
        "\n",
        "def result_to_csv(model,index):\n",
        "  predition = predict(model, index)\n",
        "  fina_id = range(len(predition))\n",
        "  test_prediction = {'Id':fina_id ,'Predicted':predition }\n",
        "  df = pd.DataFrame(test_prediction)\n",
        "  df.to_csv('best_result.csv', index=False)\n",
        "\n",
        "  return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zKVgG8isot6"
      },
      "source": [
        "## **Use Trained Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17PYriIJFrBy"
      },
      "source": [
        "### **Best Model**\n",
        "\n",
        "\n",
        "embeddeing = word2vec+bert\n",
        "\n",
        "attention = General\n",
        "\n",
        "crf = True\n",
        "\n",
        "layers = 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO6dBt4PB_8z"
      },
      "source": [
        "# load model\n",
        "id = '1gFRJPxJ6_KHVwLl4tOeJCEa04p6SrhWy' \n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('best_model_trian.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWKqivEEK2Ob"
      },
      "source": [
        "best_model_load = torch.load(\"best_model_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4bA5IsKF3tz",
        "outputId": "92250d9f-3a7c-4da3-8682-810460cca6aa"
      },
      "source": [
        "best_model_f1 = get_f1score(best_model_load)\n",
        "print(\"The F1 score of the best model: %.4f\" %(best_model_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the best model: 0.8269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gnd_p6XkcmD6"
      },
      "source": [
        "Predict in test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "69wCkUX1ck95",
        "outputId": "b0360410-cc35-43de-b73e-be8533239008"
      },
      "source": [
        "result_to_csv(best_model_load, test_input_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>B-Person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>B-Person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>B-Temporal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5229</th>\n",
              "      <td>5229</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5230</th>\n",
              "      <td>5230</td>\n",
              "      <td>B-Organisation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5231</th>\n",
              "      <td>5231</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5232</th>\n",
              "      <td>5232</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5233</th>\n",
              "      <td>5233</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5234 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Id       Predicted\n",
              "0        0        B-Person\n",
              "1        1               O\n",
              "2        2        B-Person\n",
              "3        3               O\n",
              "4        4      B-Temporal\n",
              "...    ...             ...\n",
              "5229  5229               O\n",
              "5230  5230  B-Organisation\n",
              "5231  5231               O\n",
              "5232  5232               O\n",
              "5233  5233               O\n",
              "\n",
              "[5234 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbPgIhZCGUrQ"
      },
      "source": [
        "### **Other Attemps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z18I7sjHGZ_t"
      },
      "source": [
        "#### **Base**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKR-a3bOGkLD"
      },
      "source": [
        "# load model\n",
        "id = '1jdA7ew4VrmfnK6af4K1Q6OY3sm6DRCXR'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Base_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2tu3v-9yZay"
      },
      "source": [
        "Base_model_load = torch.load(\"Base_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZW6i5B8Gq6u",
        "outputId": "24ecd9ba-c262-4b38-c95f-99fe7dcd47b3"
      },
      "source": [
        "Base_model_f1 = get_f1score(Base_model_load)\n",
        "print(\"The F1 score of the Base_model with using CRF: %.4f\" %(Base_model_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the Base_model with using CRF: 0.7154\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIh0pU8kG1JA"
      },
      "source": [
        "#### **Different input embedding model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAHpj1-uHssi"
      },
      "source": [
        "\n",
        "Layer = 2\n",
        "\n",
        "Input embedding = pos\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BpaNsw5IQt3"
      },
      "source": [
        "# load model\n",
        "id = '1_uB3crXU4wWSJZsW0Mif8-t8QksjcpHh'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('general_pos_trian.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEfkUkNk-lpW"
      },
      "source": [
        "general_pos_load = torch.load(\"general_pos_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQvcP_6dIY7J",
        "outputId": "4cb23dcf-f115-46d7-c5cc-de8fb9a600d7"
      },
      "source": [
        "general_pos_f1 = get_f1score(general_pos_load)\n",
        "print(\"The F1 score of the general method with pos: %.4f\" %(general_pos_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with pos: 0.7842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md5gBwXWIfeh"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  dependency parse\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3YsbmY6I76l"
      },
      "source": [
        "# load model\n",
        "id = '1pejxvtGVLfBeS699F6uuhjx80TeAcbIs'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('general_parse_trian.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfmJahbD-t9g"
      },
      "source": [
        "general_parse_load = torch.load(\"general_parse_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E_rsNASJBnL",
        "outputId": "2e910864-45c7-44af-93bf-389e83f2018e"
      },
      "source": [
        "general_parse_f1 = get_f1score(general_parse_load)\n",
        "print(\"The F1 score of the general method with parse: %.4f\" %(general_parse_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with parse: 0.7685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ74JU4qJd-z"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  Word2Vec\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2AU8bvXJfF3"
      },
      "source": [
        "# load model\n",
        "id = '1keJsOA4BJgS0g-8YKC-k_n4MVTFcdn6R'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('general_w2v_trian.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI_t6OXv-04I"
      },
      "source": [
        "general_w2v_load = torch.load(\"general_w2v_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVFmSLOSJ7tk",
        "outputId": "78193769-560e-4382-ee9f-afd2b66b73e4"
      },
      "source": [
        "general_w2v_f1 = get_f1score(general_w2v_load)\n",
        "print(\"The F1 score of the general method with w2v: %.4f\" %(general_w2v_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with w2v: 0.8125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuHy1rctKG9L"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  Bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y9qeBxDKIm0"
      },
      "source": [
        "# load model\n",
        "id = '1SXnwlqx0zhiiE0xLzf1rxwcti1cGwJvW'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('general_bert_trian.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH8yOLIc-9cf"
      },
      "source": [
        "general_bert_load = torch.load(\"general_bert_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3_JX65nKXJR",
        "outputId": "0726c2cf-2a21-49fd-b41f-fa51b3f47939"
      },
      "source": [
        "general_bert_f1_ = get_f1score(general_bert_load)\n",
        "print(\"The F1 score of the general method with bert: %.4f\" %(general_bert_f1_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with bert: 0.8129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICudMhG6KYlv"
      },
      "source": [
        "#### **Different attention startegy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMG6WoDgN1lc"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = Scaled Dot-product\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjtems6RN2st"
      },
      "source": [
        "# load model\n",
        "id = '1OVTI_S6wsHTN9CNjZx8r08Jhwc4lqcy8'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('scale_model_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0Xwc9eN_7cG"
      },
      "source": [
        "scale_load = torch.load(\"scale_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YQF5s9IN_Co",
        "outputId": "6221dcac-16e5-47c1-ca80-2f06af51fb1b"
      },
      "source": [
        "scale_model_f1 = get_f1score(scale_load)\n",
        "print(\"The F1 score of the Scaled Dot-product method with using CRF: %.4f\" %(scale_model_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the Scaled Dot-product method with using CRF: 0.8267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDUiAmDkODoI"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = Dot-product\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arAZaFrqOajO"
      },
      "source": [
        "# load model\n",
        "id = '1hBQWN6hC4jD6GU6A3JdSo6z77z7whjk-'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('dot_model_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oHtJ8PvAFWo"
      },
      "source": [
        "dot_load = torch.load(\"dot_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayS5OWciOg1r",
        "outputId": "a5b0a5d6-db5f-45a6-cd77-77b28af15678"
      },
      "source": [
        "dot_model_f1 = get_f1score(dot_load)\n",
        "print(\"The F1 score of the Dot-product method with using CRF: %.4f\" %(dot_model_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the Dot-product method with using CRF: 0.8153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPXKF59_OntZ"
      },
      "source": [
        "#### **Different Stacked layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKmgkQBVOrpX"
      },
      "source": [
        "Layer = 1\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9DvjUMWOsn7"
      },
      "source": [
        "# load model\n",
        "id = '1iEVFWkBgEsmoUduPuLvsJTT91spYWh2Q'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('layers1_model_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFP4c5T4Aea0"
      },
      "source": [
        "layer1_load = torch.load(\"layers1_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWCzAnHYOy9A",
        "outputId": "5004eb85-4819-4894-bac9-8a2270437e42"
      },
      "source": [
        "layer1_f1 = get_f1score(layer1_load)\n",
        "print(\"The F1 score of the general method with using CRF (layer1): %.4f\" %(layer1_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with using CRF (layer1): 0.8121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhEhfGpaO7Hy"
      },
      "source": [
        "Layer = 4\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5XpNzklO78G"
      },
      "source": [
        "# load model\n",
        "id = '1mpJiH_w3rSPwGVFCmXa23kGl1JBoOfD2'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('layers4_model_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NexePS7sP3JV"
      },
      "source": [
        "layer4_load = torch.load(\"layers4_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkXwlLY_PAHX",
        "outputId": "11fff2ee-8bee-4d34-c56c-bcdbf15d3a47"
      },
      "source": [
        "layer4_f1 = get_f1score(layer4_load)\n",
        "print(\"The F1 score of the general method with using CRF (layer4): %.4f\" %(layer4_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method with using CRF (layer4): 0.7874\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAFXaQT-PPko"
      },
      "source": [
        "#### **with/without CRF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAKEY3nOPUTW"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Without using Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raK7HhWfPQX1"
      },
      "source": [
        "# load model\n",
        "id = '1NeknO3pF8Wn7z4w_NYAvurbzgJpVC9lD'\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('withoutCrf_model_train.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWFHsurSA-ow"
      },
      "source": [
        "withoutCrf_load = torch.load(\"withoutCrf_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH4YWSHpPbq9",
        "outputId": "dc1dcc79-6812-44c1-c8fb-128578ee3883"
      },
      "source": [
        "withoutCrf_model_f1 = get_f1score(withoutCrf_load)\n",
        "print(\"The F1 score of the general method without using CRF: %.4f\" %(withoutCrf_model_f1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The F1 score of the general method without using CRF: 0.7192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z-u3gLcDRC5"
      },
      "source": [
        "#  **5 - Train and Evaluation Log**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQceTpr9mNjn"
      },
      "source": [
        "### **Best Model**\n",
        "\n",
        "\n",
        "embeddeing = word2vec+bert\n",
        "\n",
        "attention = General\n",
        "\n",
        "crf = True\n",
        "\n",
        "layers = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRFQdTxkHGeF"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMa7vBHFI6g9"
      },
      "source": [
        "EMBEDDING_DIM = word_bert_embedding_matrix.shape[1] \n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "embedding_matrix = word_bert_embedding_matrix\n",
        "best_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1RbE86KHLjQ"
      },
      "source": [
        "##### **Train and Evaluation Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sSbdpRewIJCV"
      },
      "source": [
        "best_model_trian = train_dataset(best_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yP5WnifoII97"
      },
      "source": [
        "torch.save(best_model_trian, \"best_model_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5GDK-c_QII0x"
      },
      "source": [
        "best_model_f1 = get_f1score(best_model_trian)\n",
        "print(\"The F1 score of the best model: %.4f\" %(best_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD4OOZPbHSRz"
      },
      "source": [
        "##### **Restore the result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJhCQO3cmiM"
      },
      "source": [
        "result_to_csv(best_model_load, test_input_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQHPKGYCmr9D"
      },
      "source": [
        "### **Other Attemps**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FHnBVAM2xvM"
      },
      "source": [
        "#### **Base**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wm5qnT9fC2"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMKk0TSQq5Cl"
      },
      "source": [
        "EMBEDDING_DIM = word_bert_embedding_matrix.shape[1]\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "embedding_matrix = word_bert_embedding_matrix\n",
        "base_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD6EL1mD9joc"
      },
      "source": [
        "##### **Train and Evaluation Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ice7dY1qzyR"
      },
      "source": [
        "Base_train = train_dataset(base_model)\n",
        "torch.save(Base_train, \"Base_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgrqwqs0ydxs"
      },
      "source": [
        "Base_model_f1 = get_f1score(Base_train)\n",
        "print(\"The F1 score of the Base_model with using CRF: %.4f\" %(Base_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FNlEYl020ld"
      },
      "source": [
        "#### **Different input embedding model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7kHVdvmziOV"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GiOJlQSBC7I"
      },
      "source": [
        "Static"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV4TOjPOJvHp"
      },
      "source": [
        "# (vocab_size, tag_to_ix, embedding_dim, embedding_matrix, hidden_dim, stacked_layers, use_crf = True, attention_method = None)\n",
        "\n",
        "HIDDEN_DIM = 200\n",
        "EMBEDDING_DIM = 50\n",
        "\n",
        "\n",
        "embedding_matrix = pos_embedding_matrix\n",
        "general_pos_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)\n",
        "\n",
        "embedding_matrix = parse_embedding_matrix\n",
        "general_parse_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)\n",
        "\n",
        "embedding_matrix =w2v_embedding_matrix\n",
        "general_w2v_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iHf1FDfBESr"
      },
      "source": [
        "Dynamic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFn8IGrKB-F1"
      },
      "source": [
        "HIDDEN_DIM = 200\n",
        "EMBEDDING_DIM = 768\n",
        "\n",
        "embedding_matrix = bert_embedding_matrix\n",
        "general_bert_model = Design_BiLSTM_CRF(len(bert_embedding_matrix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyFPWOdC0Wr-"
      },
      "source": [
        "Combination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYyOvAnGRB8f"
      },
      "source": [
        "EMBEDDING_DIM = 918\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "embedding_matrix = all_embedding_matrix\n",
        "general_all_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-9JZLIt0PbQ"
      },
      "source": [
        "##### **Train and Evaluation Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmc1VwFcAIVg"
      },
      "source": [
        "\n",
        "Layer = 2\n",
        "\n",
        "Input embedding = pos\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtPGNMS5Bp3l"
      },
      "source": [
        "general_pos_trian = train_dataset(general_pos_model)\n",
        "torch.save(general_pos_trian, \"general_pos_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SC1-mDv-o3r"
      },
      "source": [
        "general_pos_f1 = get_f1score(general_pos_trian)\n",
        "print(\"The F1 score of the general method with pos: %.4f\" %(general_pos_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7Sx7ZlIBVFS"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  dependency parse\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99nmKU16BqTK"
      },
      "source": [
        "general_parse_trian = train_dataset(general_parse_model)\n",
        "torch.save(general_parse_trian, \"general_parse_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGxDeka5-t3A"
      },
      "source": [
        "general_parse_f1 = get_f1score(general_parse_trian)\n",
        "print(\"The F1 score of the general method with parse: %.4f\" %(general_parse_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4blYhpGuBiPu"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  Word2Vec\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2OrzXLNBquz"
      },
      "source": [
        "general_w2v_trian = train_dataset(general_w2v_model)\n",
        "torch.save(general_w2v_trian, \"general_w2v_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctZgUb0H-2Ll"
      },
      "source": [
        "general_w2v_f1 = get_f1score(general_w2v_trian)\n",
        "print(\"The F1 score of the general method with w2v: %.4f\" %(general_w2v_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrSgEd9snUoF"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding =  Bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYp8kVCDBraH"
      },
      "source": [
        "general_bert_trian = train_dataset(general_bert_model)\n",
        "torch.save(general_bert_trian, \"general_bert_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E60yGDG--gm"
      },
      "source": [
        "general_bert_f1_ = get_f1score(general_bert_trian)\n",
        "print(\"The F1 score of the general method with bert: %.4f\" %(general_bert_f1_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg8Yfdk1yr1p"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf\n",
        "\n",
        "Note: Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfRVHcSFytWg"
      },
      "source": [
        "general_word_bert_trian = train_dataset(general_bert_model)\n",
        "torch.save(general_bert_trian, \"general_word_bert_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYK2klxWy0FP"
      },
      "source": [
        "general_word_bert_f1_ = get_f1score(general_word_bert_trian)\n",
        "print(\"The F1 score of the general method with bert: %.4f\" %(general_word_bert_f1_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j-_X_X5Bwy9"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + pos + dependency parse + Bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x5PznPsBs3c"
      },
      "source": [
        "general_all_trian = train_dataset(general_all_model)\n",
        "torch.save(general_all_trian, \"general_all_trian.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S_7TbSv_aa4"
      },
      "source": [
        "general__all_f1 = get_f1score(general_all_trian)\n",
        "print(\"The F1 score of the general method with all: %.4f\" %(general__all_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlnX0pWL23o1"
      },
      "source": [
        "#### **Different attention strategy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XbcwamE5gkr"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMQoF0ga_r3Z"
      },
      "source": [
        "HIDDEN_DIM = 200\n",
        "# 50 word2vec + 768 Bert\n",
        "EMBEDDING_DIM = 818\n",
        "\n",
        "\n",
        "embedding_matrix = word_bert_embedding_matrix\n",
        "scale_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"Scaled Dot-product\").to(device)\n",
        "general_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)\n",
        "dot_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"Dot-product\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj4y-0W25mM6"
      },
      "source": [
        "##### **Train and Evaluation Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGfVv-1ZFBDQ"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = Scaled Dot-product\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruX64QaeE_5S"
      },
      "source": [
        "scale_model_train = train_dataset(scale_model)\n",
        "torch.save(scale_model_train, \"scale_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2V_HXnk_7U4"
      },
      "source": [
        "scale_model_f1 = get_f1score(scale_model_train)\n",
        "print(\"The F1 score of the Scaled Dot-product method with using CRF: %.4f\" %(scale_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MllwhLAxFNpm"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf\n",
        "\n",
        "Note: Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm73nFSnFOCM"
      },
      "source": [
        "general_model_train = train_dataset(general_model)\n",
        "torch.save(general_model_train, \"general_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-B2WcQJACwm"
      },
      "source": [
        "general_model_f1 = get_f1score(general_model_train)\n",
        "print(\"The F1 score of the general method with using CRF: %.4f\" %(general_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXIV4mZmFXGi"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = Dot-product\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAY-fP7g2xBc"
      },
      "source": [
        "dot_model_train = train_dataset(dot_model)\n",
        "torch.save(dot_model_train, \"dot_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMHkpLDZAFUG"
      },
      "source": [
        "dot_model_f1 = get_f1score(dot_model_train)\n",
        "print(\"The F1 score of the Dot-product method with using CRF: %.4f\" %(dot_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfCde8mV26ml"
      },
      "source": [
        "#### **Different Stacked layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U99yjnS68--s"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tul4ttJmAXTV"
      },
      "source": [
        "HIDDEN_DIM = 200\n",
        "# 50 word2vec + 768 Bert\n",
        "EMBEDDING_DIM = 818\n",
        "\n",
        "\n",
        "embedding_matrix = word_bert_embedding_matrix\n",
        "layers1_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 1, use_crf = True, attention_method = \"General\").to(device)\n",
        "layers2_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)\n",
        "layers4_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 4, use_crf = True, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn9QtRk-9FQh"
      },
      "source": [
        "##### **Train and Evaluation Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46JEH7wxAQL-"
      },
      "source": [
        "Layer = 1\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aekGGk0nAPFf"
      },
      "source": [
        "layers1_model_train = train_dataset(layers1_model)\n",
        "torch.save(layers1_model_train, \"layers1_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9rNsSUAeTr"
      },
      "source": [
        "layer1_f1 = get_f1score(layers1_model_train)\n",
        "print(\"The F1 score of the general method with using CRF (layer1): %.4f\" %(layer1_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz-C5OCwFzNa"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf\n",
        "\n",
        "Note: Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dc035TzFH7P"
      },
      "source": [
        "layers2_model_train = train_dataset(layers2_model)\n",
        "torch.save(layers2_model_train, \"layers2_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1tqyrT2Jmi0"
      },
      "source": [
        "layer2_f1 = get_f1score(layers2_model_train)\n",
        "print(\"The F1 score of the general method with using CRF (layer2): %.4f\" %(layer2_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s5bgtqQPxHG"
      },
      "source": [
        "Layer = 4\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t2NrMP7Pydl"
      },
      "source": [
        "layers4_model_train = train_dataset(layers4_model)\n",
        "torch.save(layers4_model_train, \"layers4_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2lwJGg9P59_"
      },
      "source": [
        "layer4_f1 = get_f1score(layers4_model_train)\n",
        "print(\"The F1 score of the general method with using CRF (layer4): %.4f\" %(layer4_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULqI10f129LE"
      },
      "source": [
        "#### **with/without CRF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEuEp95F9LxY"
      },
      "source": [
        "##### **Initialize Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2L04RTx4H5AX"
      },
      "source": [
        "HIDDEN_DIM = 200\n",
        "# 50 word2vec + 768 Bert\n",
        "EMBEDDING_DIM = 818\n",
        "\n",
        "\n",
        "embedding_matrix = word_bert_embedding_matrix\n",
        "crf_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = True, attention_method = \"General\").to(device)\n",
        "withoutCrf_model = Design_BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, stacked_layers = 2, use_crf = False, attention_method = \"General\").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAqchzua9RQp"
      },
      "source": [
        "##### **Train and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsVfJx9YAuj7"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Use Crf\n",
        "\n",
        "Note: Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V94vMx8ZH49l"
      },
      "source": [
        "crf_model_train = train_dataset(crf_model)\n",
        "torch.save(crf_model_train, \"crf_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWBhATJ7A2JJ"
      },
      "source": [
        "crf_model_f1 = get_f1score(crf_model_train)\n",
        "print(\"The F1 score of the general method without using CRF: %.4f\" %(crf_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtwnaOiQA3pd"
      },
      "source": [
        "Layer = 2\n",
        "\n",
        "Input embedding = word2vec + bert\n",
        "\n",
        "Attention = General\n",
        "\n",
        "Without using Crf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACi4WTRrA2C6"
      },
      "source": [
        "withoutCrf_model_train = train_dataset(withoutCrf_model)\n",
        "torch.save(withoutCrf_model_train, \"withoutCrf_model_train.pth\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqc0tsQ1A-mi"
      },
      "source": [
        "withoutCrf_model_f1 = get_f1score(withoutCrf_model_train)\n",
        "print(\"The F1 score of the general method without using CRF: %.4f\" %(withoutCrf_model_f1))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}